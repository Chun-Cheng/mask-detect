{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_persons(image):\n",
    "    model = YOLO(\"../weights/yolov9e-seg.pt\")\n",
    "    classes_ids = [0]  # person\n",
    "    conf = 0.2\n",
    "\n",
    "    output = []\n",
    "\n",
    "    results = model.predict(image, conf=conf)\n",
    "    result = results[0]\n",
    "    for mask, box in zip(result.masks.xy, result.boxes):\n",
    "        points = np.int32([mask])\n",
    "        if int(box.cls[0]) in classes_ids:\n",
    "\n",
    "            # Crop the image\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "            cropped_img = image[y1:y2, x1:x2]\n",
    "\n",
    "            # Create a mask for the cropped image\n",
    "            mask_img = np.zeros_like(cropped_img)\n",
    "            mask_points = points - [x1, y1]\n",
    "            cv2.fillPoly(mask_img, mask_points, (255, 255, 255))\n",
    "\n",
    "            # Apply the mask to the cropped image\n",
    "            masked_cropped_img = cv2.bitwise_and(cropped_img, mask_img)\n",
    "\n",
    "            # add person to output\n",
    "            output.append({\n",
    "                \"image\": masked_cropped_img,\n",
    "                \"box\": box,\n",
    "                \"mask\": mask\n",
    "            })\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_clothes(image):\n",
    "    model = YOLO(\"../weights/clothes.pt\")\n",
    "\n",
    "    output = []\n",
    "    \n",
    "    results = model.predict(image)\n",
    "    result = results[0]\n",
    "    for box in result.boxes:\n",
    "        output.append({\n",
    "            \"image\": image,\n",
    "            \"box\": box\n",
    "        })\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input (change the path to your image path)\n",
    "image_path = \"../dataset/clothes/test/mk.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detection process\n",
    "\n",
    "image = cv2.imread(os.path.join(image_path))\n",
    "\n",
    "# show the original image\n",
    "plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "classes = [\"mask\", \"hat\", \"light_top\", \"heavy_top\", \"pants\", \"shorts_skirt\"]\n",
    "classes_id = [0]\n",
    "colors = [(0, 255, 0), (0, 0, 255)]\n",
    "\n",
    "mask_person_count = 0\n",
    "final_image = image.copy()\n",
    "persons = detect_persons(image)\n",
    "print(f\"{len(persons)} people detected\")\n",
    "for person in persons:\n",
    "    clothes = detect_clothes(person[\"image\"])\n",
    "    # print(f\"{len(clothes)} clothes detected on this person:\", end=\" \")\n",
    "\n",
    "    # add the bounding box and semi-transparent color mask to final_image\n",
    "    x1, y1, x2, y2 = map(int, person[\"box\"].xyxy[0])\n",
    "    color_number = 0\n",
    "    cv2.rectangle(final_image, (x1, y1), (x2, y2), colors[color_number], 5)\n",
    "    # cv2.putText(final_image, f\"person {person['box'].conf[0]:.2f}\", (x1, y1), cv2.FONT_HERSHEY_SIMPLEX, 0.5, colors[color_number], 2)\n",
    "\n",
    "    person_image = person[\"image\"]\n",
    "\n",
    "    # # show original person image\n",
    "    # plt.imshow(cv2.cvtColor(person_image, cv2.COLOR_BGR2RGB))\n",
    "    # plt.axis('off')\n",
    "    # plt.show()\n",
    "    # # save the image\n",
    "    # cv2.imwrite(\"person.jpg\", person_image)\n",
    "\n",
    "    for cloth in clothes:\n",
    "        if cloth[\"box\"].cls[0] in classes_id:\n",
    "            print(f\"{classes[int(cloth[\"box\"].cls[0])]}: {cloth[\"box\"].conf[0]:.2f}\")\n",
    "            # print(cloth[\"box\"])\n",
    "            x1, y1, x2, y2 = map(int, cloth[\"box\"].xyxy[0])\n",
    "\n",
    "            # add the bounding box to person_image\n",
    "            color_number = 1\n",
    "            cv2.rectangle(person_image, (x1, y1), (x2, y2), colors[color_number], 3)\n",
    "            # add the class name\n",
    "            # cv2.putText(person_image, f\"{classes[int(cloth[\"box\"].cls[0])]} {cloth[\"box\"].conf[0]:.2f}\", (x1, y1), cv2.FONT_HERSHEY_SIMPLEX, 0.5, colors[color_number], 2)\n",
    "\n",
    "            # add the bounding box to final_image\n",
    "            x1, y1, x2, y2 = map(int, cloth[\"box\"].xyxy[0])\n",
    "            x1 += int(person[\"box\"].xyxy[0][0])\n",
    "            y1 += int(person[\"box\"].xyxy[0][1])\n",
    "            x2 += int(person[\"box\"].xyxy[0][0])\n",
    "            y2 += int(person[\"box\"].xyxy[0][1])\n",
    "            # color_number = 1\n",
    "            cv2.rectangle(final_image, (x1, y1), (x2, y2), colors[color_number], 3)\n",
    "            # cv2.putText(final_image, f\"{classes[int(cloth['box'].cls[0])]} {cloth['box'].conf[0]:.2f}\", (x1, y1), cv2.FONT_HERSHEY_SIMPLEX, 0.5, colors[color_number], 2)\n",
    "\n",
    "            # # Draw the mask\n",
    "            # points = np.int32([cloth[\"mask\"]])\n",
    "            # cv2.polylines(person_image, points, True, (255, 0, 0), 1)\n",
    "            # cv2.fillPoly(person_image, points, colors[color_number])\n",
    "\n",
    "            mask_person_count += 1\n",
    "            break # detect only one mask per person\n",
    "\n",
    "    plt.imshow(cv2.cvtColor(person_image, cv2.COLOR_BGR2RGB))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "plt.imshow(cv2.cvtColor(final_image, cv2.COLOR_BGR2RGB))\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "print(f\"{mask_person_count} people are wearing masks in {len(persons)} people. (At least {mask_person_count/len(persons)*100:.2f}%)\")\n",
    "\n",
    "# save the image\n",
    "cv2.imwrite(\"output.jpg\", final_image)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
