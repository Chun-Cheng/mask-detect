{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Crop People Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: https://medium.com/@Mert.A/how-to-segment-objects-with-yolov9-71a3439c8b10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!uv sync"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"../weights/yolov9e-seg.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmenting Objects in Images with YOLOv9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_path = \"../dataset/people\"\n",
    "save_path = \"../dataset/person\"\n",
    "save_file_num = 1\n",
    "\n",
    "classes_ids = [0]  # person\n",
    "conf = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_files = os.listdir(source_path)\n",
    "for image_file in image_files:\n",
    "    img = cv2.imread(os.path.join(source_path, image_file))\n",
    "\n",
    "    results = model.predict(img, conf=conf)\n",
    "    # colors = [random.choices(range(256), k=3) for _ in classes_ids]\n",
    "    print(results)\n",
    "\n",
    "    result = results[0]\n",
    "    for mask, box in zip(result.masks.xy, result.boxes):\n",
    "        points = np.int32([mask])\n",
    "        if int(box.cls[0]) in classes_ids:\n",
    "            img_copy = img.copy()\n",
    "\n",
    "            # Draw the mask\n",
    "            # cv2.polylines(img_copy, points, True, (255, 0, 0), 1)\n",
    "            # color_number = classes_ids.index(int(box.cls[0]))\n",
    "            # cv2.fillPoly(img_copy, points, colors[color_number])\n",
    "\n",
    "            # Crop the image\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "            cropped_img = img[y1:y2, x1:x2]\n",
    "\n",
    "            # Create a mask for the cropped image\n",
    "            mask_img = np.zeros_like(cropped_img)\n",
    "            mask_points = points - [x1, y1]\n",
    "            cv2.fillPoly(mask_img, mask_points, (255, 255, 255))\n",
    "\n",
    "            # Apply the mask to the cropped image\n",
    "            masked_cropped_img = cv2.bitwise_and(cropped_img, mask_img)\n",
    "\n",
    "            # show images\n",
    "            # cv2.imshow(\"Masked Cropped Image\", masked_cropped_img)\n",
    "            # cv2.imshow(\"Image\", img_copy)\n",
    "            # cv2.waitKey(0)\n",
    "\n",
    "            # save image\n",
    "            cv2.imwrite(os.path.join(save_path, f\"image_{save_file_num:06d}.jpg\"), masked_cropped_img)\n",
    "            save_file_num += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Label People's Clothes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use tools like https://www.makesense.ai to label images and export annotations as YOLO format.\n",
    "\n",
    "If you need to modify hundreds of thousands of annotation files, you can use `src/train_utility.ipynb` to do this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Train the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: https://docs.ultralytics.com/modes/train/#usage-examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train on multi-GPU or Apple Silicon, please read the reference article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"../weights/yolo11s.pt\")\n",
    "results = model.train(data=\"../dataset/mask/mask.yaml\", epochs=16, batch=-1, imgsz=640)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the training complete, move the `src/runs/detect/train/weights/best.pt` to `weights/clothes.pt`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
